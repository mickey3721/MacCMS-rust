use crate::dto::{Category, JsonResponse, VideoListResponse, VodApiListEntry};
use crate::models::{Binding, Collection, PlaySource, PlayUrl, Vod};
use actix_web::{web, HttpResponse, Responder};
use chrono::Timelike;
use mongodb::bson::{doc, oid::ObjectId, DateTime};
use mongodb::Database;
use reqwest;
use serde::{Deserialize, Serialize};
use std::time::{SystemTime, UNIX_EPOCH};

// è§£ææ’­æ”¾åœ°å€å‡½æ•°
fn parse_play_urls(vod_play_from: &str, vod_play_url: &Option<String>) -> Vec<PlaySource> {
    let mut play_sources = Vec::new();

    if let Some(play_url) = vod_play_url {
        // æŒ‰,ç¬¦å·åˆ†å‰²æ’­æ”¾æº
        let sources: Vec<&str> = vod_play_from.split(',').collect();

        // å¦‚æœplay_urlåŒ…å«#å·ï¼Œè¯´æ˜æ˜¯å¤šé›†å†…å®¹
        if play_url.contains('#') {
            // å¤šé›†å†…å®¹ï¼šæŒ‰#åˆ†å‰²å„é›†
            let episodes: Vec<&str> = play_url
                .split('#')
                .filter(|episode| !episode.trim().is_empty()) // è¿‡æ»¤ç©ºçš„episode
                .collect();

            for (i, source_name) in sources.iter().enumerate() {
                let mut urls = Vec::new();

                // å¤„ç†æ¯ä¸€é›†
                for episode in episodes.iter() {
                    if let Some((name, url)) = episode.split_once('$') {
                        urls.push(PlayUrl {
                            name: name.to_string(),
                            url: url.to_string(),
                        });
                    } else {
                        // å¦‚æœæ²¡æœ‰$åˆ†å‰²ç¬¦ï¼Œå¯èƒ½æ˜¯ç‰¹æ®Šæƒ…å†µ
                        urls.push(PlayUrl {
                            name: episode.to_string(),
                            url: String::new(),
                        });
                    }
                }

                if !urls.is_empty() {
                    play_sources.push(PlaySource {
                        source_name: source_name.trim().to_string(),
                        urls,
                    });
                }
            }
        } else {
            // å•é›†å†…å®¹ï¼šç›´æ¥æŒ‰$åˆ†å‰²
            for source_name in sources.iter() {
                let mut urls = Vec::new();

                if let Some((name, url)) = play_url.split_once('$') {
                    urls.push(PlayUrl {
                        name: name.to_string(),
                        url: url.to_string(),
                    });
                } else {
                    // å¦‚æœæ²¡æœ‰$åˆ†å‰²ç¬¦ï¼Œå¯èƒ½æ˜¯çº¯URL
                    urls.push(PlayUrl {
                        name: String::new(),
                        url: play_url.to_string(),
                    });
                }

                if !urls.is_empty() {
                    play_sources.push(PlaySource {
                        source_name: source_name.trim().to_string(),
                        urls,
                    });
                }
            }
        }
    }

    play_sources
}

#[derive(Deserialize)]
pub struct CollectCategoriesQuery {
    url: String,
}

#[derive(Deserialize)]
pub struct CollectVideosQuery {
    url: String,
    page: Option<u32>,
    limit: Option<u32>,
    #[serde(rename = "type")]
    type_id: Option<String>,
    wd: Option<String>,
}

#[derive(Deserialize)]
pub struct CollectStartRequest {
    collection_id: String,
    source_flag: String,
    api_url: String,
    #[serde(rename = "type")]
    collect_type: String,
    video_ids: Option<Vec<String>>,
    hours: Option<u32>,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct CollectProgress {
    pub status: String,
    pub current_page: u32,
    pub total_pages: u32,
    pub success: u32,
    pub failed: u32,
    pub log: String,
}

impl Default for CollectProgress {
    fn default() -> Self {
        Self {
            status: "unknown".to_string(),
            current_page: 0,
            total_pages: 0,
            success: 0,
            failed: 0,
            log: "æœªçŸ¥çŠ¶æ€".to_string(),
        }
    }
}

#[derive(Serialize)]
pub struct CollectProgressResponse {
    success: bool,
    progress: CollectProgress,
}

// ç±»å‹åˆ«åç®€åŒ–å¤æ‚ç±»å‹
type TaskProgressMap = std::collections::HashMap<
    String,
    (CollectProgress, String, Option<tokio::task::JoinHandle<()>>),
>;
type TaskProgressStore = tokio::sync::RwLock<TaskProgressMap>;

// å…¨å±€ä»»åŠ¡è¿›åº¦å­˜å‚¨
static TASK_PROGRESS: std::sync::OnceLock<TaskProgressStore> = std::sync::OnceLock::new();

// åˆå§‹åŒ–ä»»åŠ¡è¿›åº¦å­˜å‚¨
fn get_task_progress_store() -> &'static TaskProgressStore {
    TASK_PROGRESS.get_or_init(|| tokio::sync::RwLock::new(std::collections::HashMap::new()))
}

// è·å–ä»»åŠ¡è¿›åº¦
pub async fn get_task_progress(task_id: &str) -> Option<CollectProgress> {
    let store = get_task_progress_store();
    let progress_map = store.read().await;
    progress_map
        .get(task_id)
        .map(|(progress, _, _)| progress.clone())
}

// æ›´æ–°ä»»åŠ¡è¿›åº¦
async fn update_task_progress(task_id: &str, progress: CollectProgress, collection_name: String) {
    let store = get_task_progress_store();
    let mut progress_map = store.write().await;
    if let Some((current_progress, current_name, handle)) = progress_map.get_mut(task_id) {
        *current_progress = progress;
        *current_name = collection_name;
        // ä¿æŒåŸæœ‰çš„handleä¸å˜ï¼Œä¸éœ€è¦å…‹éš†
    } else {
        progress_map.insert(task_id.to_string(), (progress, collection_name, None));
    }
}

// åœæ­¢ä»»åŠ¡
pub async fn stop_task(task_id: &str) -> bool {
    let store = get_task_progress_store();
    let mut progress_map = store.write().await;

    if let Some((mut progress, collection_name, handle)) = progress_map.remove(task_id) {
        // å–æ¶ˆä»»åŠ¡
        if let Some(task_handle) = handle {
            task_handle.abort();
        }

        // æ ‡è®°ä»»åŠ¡ä¸ºå·²åœæ­¢
        progress.status = "stopped".to_string();
        progress.log = "ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢".to_string();

        // å°†ä»»åŠ¡é‡æ–°æ’å…¥ï¼Œä½†çŠ¶æ€ä¸ºå·²åœæ­¢ä¸”æ¸…é™¤å¥æŸ„
        progress_map.insert(task_id.to_string(), (progress, collection_name, None));

        true
    } else {
        false
    }
}

// è·å–æ‰€æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡
pub async fn get_all_running_tasks() -> Vec<serde_json::Value> {
    let store = get_task_progress_store();
    let progress_map = store.read().await;

    let mut tasks = Vec::new();
    let now = chrono::Utc::now();

    for (task_id, (progress, collection_name, _)) in progress_map.iter() {
        // åªè¿”å›è¿è¡Œä¸­çš„ä»»åŠ¡
        let should_include = progress.status == "running";

        if should_include {
            tasks.push(serde_json::json!({
                "task_id": task_id,
                "collection_name": collection_name,
                "status": progress.status,
                "current_page": progress.current_page,
                "total_pages": progress.total_pages,
                "success": progress.success,
                "failed": progress.failed,
                "log": progress.log,
                "start_time": format!("{:02}:{:02}:{:02}", now.hour(), now.minute(), now.second())
            }));
        }
    }

    tasks
}

// è·å–é‡‡é›†æºåˆ†ç±»åˆ—è¡¨
pub async fn get_collect_categories(query: web::Query<CollectCategoriesQuery>) -> impl Responder {
    let mut api_url = query.url.clone();
    if api_url.contains('?') {
        // å¦‚æœURLå·²åŒ…å«?ï¼Œæ£€æŸ¥æ˜¯å¦ä»¥?ç»“å°¾æˆ–å·²æœ‰å‚æ•°
        if api_url.ends_with('?') {
            api_url.push_str("ac=list");
        } else {
            api_url.push_str("&ac=list");
        }
    } else {
        api_url.push_str("?ac=list");
    }

    match reqwest::get(&api_url).await {
        Ok(response) => match response.text().await {
            Ok(response_text) => {
                // eprintln!("API Response: {}", response_text);
                match serde_json::from_str::<JsonResponse<Category>>(&response_text) {
                    Ok(api_response) => {
                        if api_response.code == 1 {
                            HttpResponse::Ok().json(serde_json::json!({
                                "success": true,
                                "categories": api_response.categories
                            }))
                        } else {
                            HttpResponse::Ok().json(serde_json::json!({
                                "success": false,
                                "message": "APIè¿”å›é”™è¯¯"
                            }))
                        }
                    }
                    Err(e) => {
                        eprintln!("Failed to parse API response: {}", e);
                        HttpResponse::Ok().json(serde_json::json!({
                            "success": false,
                            "message": "è§£æAPIå“åº”å¤±è´¥"
                        }))
                    }
                }
            }
            Err(e) => {
                eprintln!("Failed to get response text: {}", e);
                HttpResponse::Ok().json(serde_json::json!({
                    "success": false,
                    "message": "è·å–å“åº”å¤±è´¥"
                }))
            }
        },
        Err(e) => {
            eprintln!("Failed to fetch categories: {}", e);
            HttpResponse::Ok().json(serde_json::json!({
                "success": false,
                "message": "è·å–åˆ†ç±»åˆ—è¡¨å¤±è´¥"
            }))
        }
    }
}

// è·å–é‡‡é›†æºè§†é¢‘åˆ—è¡¨
pub async fn get_collect_videos(query: web::Query<CollectVideosQuery>) -> impl Responder {
    let mut api_url = format!("{}?ac=detail", query.url);

    // æ·»åŠ æŸ¥è¯¢å‚æ•°
    let mut params = Vec::new();

    if let Some(page) = query.page {
        params.push(format!("pg={}", page));
    }

    if let Some(type_id) = &query.type_id {
        params.push(format!("t={}", type_id));
    }

    if let Some(wd) = &query.wd {
        params.push(format!("wd={}", urlencoding::encode(wd)));
    }

    if !params.is_empty() {
        api_url.push('&');
        api_url.push_str(&params.join("&"));
    }

    match reqwest::get(&api_url).await {
        Ok(response) => match response.text().await {
            Ok(response_text) => match serde_json::from_str::<VideoListResponse>(&response_text) {
                Ok(api_response) => {
                    if api_response.code == 1 {
                        let limit = query.limit.unwrap_or(20) as usize;
                        let total_pages = (api_response.total as f64 / limit as f64).ceil() as u32;

                        HttpResponse::Ok().json(serde_json::json!({
                            "success": true,
                            "videos": api_response.list,
                            "total": api_response.total,
                            "total_pages": total_pages
                        }))
                    } else {
                        HttpResponse::Ok().json(serde_json::json!({
                            "success": false,
                            "message": "APIè¿”å›é”™è¯¯"
                        }))
                    }
                }
                Err(e) => {
                    eprintln!("Failed to parse API response: {}", e);
                    HttpResponse::Ok().json(serde_json::json!({
                        "success": false,
                        "message": "è§£æAPIå“åº”å¤±è´¥"
                    }))
                }
            },
            Err(e) => {
                eprintln!("Failed to get response text: {}", e);
                HttpResponse::Ok().json(serde_json::json!({
                    "success": false,
                    "message": "è·å–å“åº”å¤±è´¥"
                }))
            }
        },
        Err(e) => {
            eprintln!("Failed to fetch videos: {}", e);
            HttpResponse::Ok().json(serde_json::json!({
                "success": false,
                "message": "è·å–è§†é¢‘åˆ—è¡¨å¤±è´¥"
            }))
        }
    }
}

// å¼€å§‹é‡‡é›†ä»»åŠ¡
pub async fn start_collect_task(
    db: web::Data<Database>,
    request: web::Json<CollectStartRequest>,
) -> impl Responder {
    // ç”Ÿæˆä»»åŠ¡ID
    let task_id = ObjectId::new().to_hex();

    // è·å–é‡‡é›†æºé…ç½®
    let collections_collection = db.collection::<Collection>("collections");
    let collection = match collections_collection
        .find_one(
            doc! {"_id": ObjectId::parse_str(&request.collection_id).unwrap()},
            None,
        )
        .await
    {
        Ok(Some(c)) => c,
        Ok(None) => {
            return HttpResponse::NotFound().json(serde_json::json!({
                "success": false,
                "message": "é‡‡é›†æºä¸å­˜åœ¨"
            }));
        }
        Err(e) => {
            eprintln!("Failed to get collection: {}", e);
            return HttpResponse::InternalServerError().json(serde_json::json!({
                "success": false,
                "message": "è·å–é‡‡é›†æºå¤±è´¥"
            }));
        }
    };

    // åˆå§‹åŒ–ä»»åŠ¡è¿›åº¦
    let initial_progress = CollectProgress {
        status: "running".to_string(),
        current_page: 0,
        total_pages: 1,
        success: 0,
        failed: 0,
        log: "æ­£åœ¨å¯åŠ¨é‡‡é›†ä»»åŠ¡...".to_string(),
    };
    update_task_progress(
        &task_id,
        initial_progress.clone(),
        collection.collect_name.clone(),
    )
    .await;

    // å¯åŠ¨åå°é‡‡é›†ä»»åŠ¡
    let db_clone = db.clone();
    let task_id_clone = task_id.clone();
    let collection_name_clone = collection.collect_name.clone();
    let handle = tokio::spawn(async move {
        let hours = request.hours.map(|h| h.to_string());
        let task_id_for_closure = task_id_clone.clone();
        match start_batch_collect(&db_clone, collection.clone(), hours, task_id_clone).await {
            Ok(_) => {
                // ä»»åŠ¡æ­£å¸¸å®Œæˆ
                let mut progress = get_task_progress(&task_id_for_closure)
                    .await
                    .unwrap_or_default();
                progress.status = "completed".to_string();
                progress.log = format!(
                    "é‡‡é›†å®Œæˆï¼ŒæˆåŠŸ: {}ï¼Œå¤±è´¥: {}",
                    progress.success, progress.failed
                );
                update_task_progress(&task_id_for_closure, progress, collection_name_clone).await;
            }
            Err(e) => {
                // ä»»åŠ¡å¤±è´¥
                let mut progress = get_task_progress(&task_id_for_closure)
                    .await
                    .unwrap_or_default();
                progress.status = "failed".to_string();
                progress.log = format!("é‡‡é›†å¤±è´¥: {}", e);
                update_task_progress(&task_id_for_closure, progress, collection_name_clone).await;
            }
        }
    });

    // å­˜å‚¨ä»»åŠ¡å¥æŸ„
    let store = get_task_progress_store();
    let mut progress_map = store.write().await;
    if let Some((progress, collection_name, _)) = progress_map.get_mut(&task_id) {
        *progress_map.get_mut(&task_id).unwrap() =
            (progress.clone(), collection_name.clone(), Some(handle));
    }

    HttpResponse::Ok().json(serde_json::json!({
        "success": true,
        "task_id": task_id,
        "message": "é‡‡é›†ä»»åŠ¡å·²å¯åŠ¨"
    }))
}

// è·å–é‡‡é›†è¿›åº¦
pub async fn get_collect_progress(path: web::Path<String>) -> impl Responder {
    let task_id = path.into_inner();

    if let Some(progress) = get_task_progress(&task_id).await {
        HttpResponse::Ok().json(CollectProgressResponse {
            success: true,
            progress,
        })
    } else {
        HttpResponse::Ok().json(CollectProgressResponse {
            success: false,
            progress: CollectProgress {
                status: "not_found".to_string(),
                current_page: 0,
                total_pages: 0,
                success: 0,
                failed: 0,
                log: "ä»»åŠ¡ä¸å­˜åœ¨".to_string(),
            },
        })
    }
}

// å¸¦è¶…æ—¶çš„HTTPè¯·æ±‚
async fn fetch_with_timeout(
    url: &str,
    timeout_secs: u64,
) -> Result<String, Box<dyn std::error::Error + Send + Sync>> {
    use tokio::time::{timeout, Duration};

    match timeout(Duration::from_secs(timeout_secs), reqwest::get(url)).await {
        Ok(Ok(response)) => match response.text().await {
            Ok(text) => Ok(text),
            Err(e) => Err(format!("è¯»å–å“åº”å¤±è´¥: {}", e).into()),
        },
        Ok(Err(e)) => Err(format!("è¯·æ±‚å¤±è´¥: {}", e).into()),
        Err(_) => Err("è¯·æ±‚è¶…æ—¶".into()),
    }
}

// å¸¦é‡è¯•çš„è·å–æ€»é¡µæ•°å‡½æ•°
async fn get_total_pages_with_retry(
    api_url: &str,
    max_retries: usize,
    timeout_secs: u64,
) -> Result<u32, Box<dyn std::error::Error + Send + Sync>> {
    let mut last_error: Option<Box<dyn std::error::Error + Send + Sync>> = None;

    for attempt in 1..=max_retries {
        let first_page_url = format!("{}&pg=1", api_url);

        println!("ğŸ”„ è·å–æ€»é¡µæ•° (å°è¯• {}/{})", attempt, max_retries);

        match fetch_with_timeout(&first_page_url, timeout_secs).await {
            Ok(response_text) => match serde_json::from_str::<VideoListResponse>(&response_text) {
                Ok(api_response) => {
                    if api_response.code == 1 {
                        let total_pages =
                            (api_response.total as f64 / api_response.limit as f64).ceil() as u32;
                        println!("âœ… è·å–æ€»é¡µæ•°æˆåŠŸ: {} é¡µ", total_pages);
                        return Ok(total_pages);
                    } else {
                        let error = format!("APIè¿”å›é”™è¯¯: {:?}", api_response);
                        println!("âŒ {}", error);
                        last_error = Some(error.into());
                    }
                }
                Err(e) => {
                    let error = format!("è§£æAPIå“åº”å¤±è´¥: {}", e);
                    println!("âŒ {}", error);
                    last_error = Some(error.into());
                }
            },
            Err(e) => {
                let error = format!("è·å–æ€»é¡µæ•°å¤±è´¥: {}", e);
                println!("âŒ {}", error);
                last_error = Some(error.into());
            }
        }

        // å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´å†é‡è¯•
        if attempt < max_retries {
            let delay = std::time::Duration::from_secs(2u64.pow(attempt as u32 - 1));
            println!("â³ ç­‰å¾… {} ç§’åé‡è¯•...", delay.as_secs());
            tokio::time::sleep(delay).await;
        }
    }

    Err(last_error.unwrap_or_else(|| "æœªçŸ¥é”™è¯¯".into()))
}

// æ‰¹é‡é‡‡é›†ä¸»å‡½æ•°
pub async fn start_batch_collect(
    db: &Database,
    collection: Collection,
    hours: Option<String>,
    task_id: String,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    // åˆå§‹åŒ–ä»»åŠ¡è¿›åº¦
    let initial_progress = CollectProgress {
        status: "running".to_string(),
        current_page: 0,
        total_pages: 1,
        success: 0,
        failed: 0,
        log: "æ­£åœ¨è·å–æ€»é¡µæ•°...".to_string(),
    };
    update_task_progress(
        &task_id,
        initial_progress.clone(),
        collection.collect_name.clone(),
    )
    .await;

    // æ„å»ºAPI URL
    let mut api_url = collection.collect_url.clone();
    if api_url.contains('?') {
        // å¦‚æœURLå·²åŒ…å«?ï¼Œæ£€æŸ¥æ˜¯å¦ä»¥?ç»“å°¾æˆ–å·²æœ‰å‚æ•°
        if api_url.ends_with('?') {
            api_url.push_str("ac=detail");
        } else {
            api_url.push_str("&ac=detail");
        }
    } else {
        api_url.push_str("?ac=detail");
    }

    // æ·»åŠ hourså‚æ•°
    if let Some(h) = hours {
        api_url.push_str(&format!("&h={}", h));
    }

    // è·å–æ€»é¡µæ•°ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
    let total_pages = match get_total_pages_with_retry(&api_url, 3, 30).await {
        Ok(pages) => pages,
        Err(e) => {
            eprintln!("âŒ è·å–æ€»é¡µæ•°å¤±è´¥ï¼Œå·²é‡è¯•3æ¬¡: {}", e);
            return Err(format!("è·å–æ€»é¡µæ•°å¤±è´¥: {}", e).into());
        }
    };

    // æ›´æ–°è¿›åº¦ä¿¡æ¯
    let mut progress = initial_progress;
    progress.total_pages = total_pages;
    progress.log = format!("å¼€å§‹é‡‡é›†ï¼Œæ€»é¡µæ•°: {}", total_pages);
    update_task_progress(&task_id, progress.clone(), collection.collect_name.clone()).await;

    // é€é¡µé‡‡é›†
    for page in 1..=total_pages {
        // æ£€æŸ¥ä»»åŠ¡æ˜¯å¦è¢«åœæ­¢
        if let Some(current_progress) = get_task_progress(&task_id).await {
            if current_progress.status == "stopped" {
                return Ok(()); // ä»»åŠ¡å·²è¢«åœæ­¢ï¼Œç›´æ¥è¿”å›
            }
        }

        progress.current_page = page;
        progress.log = format!("æ­£åœ¨é‡‡é›†ç¬¬ {}/{} é¡µ", page, total_pages);
        update_task_progress(&task_id, progress.clone(), collection.collect_name.clone()).await;

        let page_url = format!("{}&pg={}", api_url, page);
        if let Err(e) = collect_page(db, &collection, &page_url, &mut progress, &task_id).await {
            progress.failed += 1;
            progress.log = format!("ç¬¬ {} é¡µé‡‡é›†å¤±è´¥: {}", page, e);
            update_task_progress(&task_id, progress.clone(), collection.collect_name.clone()).await;
            continue;
        }

        // æ·»åŠ å»¶æ—¶é¿å…è¯·æ±‚è¿‡å¿«
        tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
    }

    // å®Œæˆé‡‡é›†
    progress.status = "completed".to_string();
    progress.log = format!(
        "é‡‡é›†å®Œæˆï¼ŒæˆåŠŸ: {}ï¼Œå¤±è´¥: {}",
        progress.success, progress.failed
    );
    update_task_progress(&task_id, progress, collection.collect_name).await;

    Ok(())
}

// é‡‡é›†å•é¡µæ•°æ®ï¼ˆå¸¦è¶…æ—¶ï¼‰
async fn collect_page(
    db: &Database,
    collection: &Collection,
    page_url: &str,
    progress: &mut CollectProgress,
    task_id: &str,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    let response_text = fetch_with_timeout(page_url, 30).await?;
    let api_response: VideoListResponse = serde_json::from_str(&response_text)?;

    if api_response.code != 1 {
        return Err(format!("APIè¿”å›é”™è¯¯: {:?}", api_response).into());
    }

    let mut page_success = 0;
    let mut page_failed = 0;

    for vod_data in api_response.list {
        // æ£€æŸ¥ä»»åŠ¡æ˜¯å¦è¢«åœæ­¢
        if let Some(current_progress) = get_task_progress(task_id).await {
            if current_progress.status == "stopped" {
                return Ok(()); // ä»»åŠ¡å·²è¢«åœæ­¢ï¼Œç›´æ¥è¿”å›
            }
        }

        match collect_single_video(db, collection, &vod_data).await {
            Ok(_) => page_success += 1,
            Err(e) => {
                eprintln!("é‡‡é›†è§†é¢‘å¤±è´¥ {}: {}", vod_data.vod_name, e);
                page_failed += 1;
            }
        }
    }

    progress.success += page_success;
    progress.failed += page_failed;
    progress.log = format!(
        "æœ¬é¡µé‡‡é›†å®Œæˆï¼ŒæˆåŠŸ: {}ï¼Œå¤±è´¥: {}",
        page_success, page_failed
    );
    update_task_progress(task_id, progress.clone(), collection.collect_name.clone()).await;

    Ok(())
}

// é‡‡é›†å•ä¸ªè§†é¢‘
pub async fn collect_single_video(
    db: &Database,
    collection: &Collection,
    vod_data: &VodApiListEntry,
) -> Result<bool, Box<dyn std::error::Error + Send + Sync>> {
    // æŸ¥æ‰¾åˆ†ç±»ç»‘å®š
    let bindings_collection = db.collection::<Binding>("bindings");
    let binding = bindings_collection
        .find_one(
            doc! {
                "source_flag": &collection.collect_name,
                "external_id": vod_data.type_id.to_string()
            },
            None,
        )
        .await?;

    let local_type_id = match binding {
        Some(b) => b.local_type_id,
        None => {
            eprintln!(
                "æœªæ‰¾åˆ°åˆ†ç±»ç»‘å®š: source_flag={}, external_id={}",
                collection.collect_name, vod_data.type_id
            );
            return Err("æœªæ‰¾åˆ°åˆ†ç±»ç»‘å®š".into());
        }
    };

    // æ£€æŸ¥è§†é¢‘æ˜¯å¦å·²å­˜åœ¨ï¼ˆåŸºäºvod_nameå’Œvod_yearï¼‰
    let vods_collection = db.collection::<Vod>("vods");
    let existing_vod = if let Some(ref year) = vod_data.vod_year {
        vods_collection
            .find_one(
                doc! {
                    "vod_name": &vod_data.vod_name,
                    "vod_year": year
                },
                None,
            )
            .await?
    } else {
        vods_collection
            .find_one(
                doc! {
                    "vod_name": &vod_data.vod_name
                },
                None,
            )
            .await?
    };

    let current_time = DateTime::from_millis(
        SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_millis() as i64,
    );

    if let Some(mut existing) = existing_vod {
        // æ›´æ–°ç°æœ‰è§†é¢‘ - å¤„ç†æ’­æ”¾æºæ›¿æ¢
        let new_play_sources = parse_play_urls(&vod_data.vod_play_from, &vod_data.vod_play_url);

        // æ ¹æ®source_nameåŒ¹é…æ›´æ–°æ’­æ”¾æº
        let mut updated = false;
        for new_source in new_play_sources {
            if let Some(pos) = existing
                .vod_play_urls
                .iter()
                .position(|s| s.source_name == new_source.source_name)
            {
                // æ›¿æ¢ç°æœ‰æ’­æ”¾æº
                existing.vod_play_urls[pos] = new_source;
                updated = true;
            } else {
                // æ·»åŠ æ–°æ’­æ”¾æº
                existing.vod_play_urls.push(new_source);
                updated = true;
            }
        }

        if updated {
            existing.vod_pubdate = current_time;
            existing.vod_remarks = Some(vod_data.vod_remarks.clone());
            vods_collection
                .replace_one(doc! { "_id": existing.id }, &existing, None)
                .await?;
        }

        Ok(true)
    } else {
        // åˆ›å»ºæ–°è§†é¢‘
        let new_vod = Vod {
            id: None,
            vod_name: vod_data.vod_name.clone(),
            type_id: local_type_id,
            vod_status: vod_data.vod_status.unwrap_or(1),
            vod_class: vod_data.vod_class.clone(),
            vod_pic: vod_data.vod_pic.clone(),
            vod_actor: vod_data.vod_actor.clone(),
            vod_director: vod_data.vod_director.clone(),
            vod_remarks: Some(vod_data.vod_remarks.clone()),
            vod_pubdate: current_time.clone(),
            vod_area: vod_data.vod_area.clone(),
            vod_lang: vod_data.vod_lang.clone(),
            vod_year: vod_data.vod_year.clone(),
            vod_content: vod_data.vod_content.clone(),
            vod_hits: Some(0),
            vod_hits_day: Some(0),
            vod_hits_week: Some(0),
            vod_hits_month: Some(0),
            vod_score: Some("0.0".to_string()),
            vod_play_urls: parse_play_urls(&vod_data.vod_play_from, &vod_data.vod_play_url),
        };

        // å¦‚æœå¯ç”¨äº†å›¾ç‰‡æœ¬åœ°åŒ–ï¼Œä¸‹è½½æµ·æŠ¥
        let final_vod_pic = if collection.collect_sync_pic_opt == 1 {
            if let Some(ref pic_url) = vod_data.vod_pic {
                match download_image_to_local_with_config(pic_url, collection).await {
                    Ok(local_path) => Some(local_path),
                    Err(e) => {
                        eprintln!("ä¸‹è½½å›¾ç‰‡å¤±è´¥ {}: {}", pic_url, e);
                        vod_data.vod_pic.clone()
                    }
                }
            } else {
                vod_data.vod_pic.clone()
            }
        } else {
            vod_data.vod_pic.clone()
        };

        let mut final_vod = new_vod;
        final_vod.vod_pic = final_vod_pic;

        vods_collection.insert_one(&final_vod, None).await?;
        Ok(true)
    }
}

// ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°ï¼ˆå¸¦é‡è¯•æœºåˆ¶å’Œwebpè½¬æ¢ï¼‰
async fn download_image_to_local_with_config(
    image_url: &str,
    collection: &Collection,
) -> Result<String, Box<dyn std::error::Error + Send + Sync>> {
    // åˆ›å»ºstaticç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    tokio::fs::create_dir_all("static/images").await?;

    // è·å–é‡è¯•æ¬¡æ•°å’Œwebpè½¬æ¢è®¾ç½®
    let max_retries = if collection.collect_download_retry > 0 {
        collection.collect_download_retry as usize
    } else {
        3 // é»˜è®¤é‡è¯•3æ¬¡
    };

    let convert_to_webp = collection.collect_convert_webp == 1;

    // ç”Ÿæˆæ–‡ä»¶å
    let file_extension = if convert_to_webp {
        "webp"
    } else {
        image_url.split('.').last().unwrap_or("jpg")
    };
    let file_name = format!("{}.{}", uuid::Uuid::new_v4(), file_extension);
    let local_path = format!("static/images/{}", file_name);

    // é‡è¯•ä¸‹è½½
    let mut last_error = None;
    for attempt in 1..=max_retries {
        match download_and_process_image(image_url, &local_path, convert_to_webp, attempt).await {
            Ok(_) => {
                println!("å›¾ç‰‡ä¸‹è½½æˆåŠŸ: {} (å°è¯•æ¬¡æ•°: {})", image_url, attempt);
                return Ok(format!("/static/images/{}", file_name));
            }
            Err(e) => {
                let error_msg = format!("ä¸‹è½½å¤±è´¥ (å°è¯• {}/{}): {}", attempt, max_retries, e);
                println!("{}", error_msg);
                last_error = Some(e);

                // å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´å†é‡è¯•
                if attempt < max_retries {
                    let delay = std::time::Duration::from_secs(2u64.pow(attempt as u32 - 1));
                    tokio::time::sleep(delay).await;
                }
            }
        }
    }

    // æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
    Err(last_error.unwrap_or_else(|| "æœªçŸ¥ä¸‹è½½é”™è¯¯".into()))
}

// ä¸‹è½½å¹¶å¤„ç†å›¾ç‰‡
async fn download_and_process_image(
    image_url: &str,
    local_path: &str,
    convert_to_webp: bool,
    attempt: usize,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    // ä¸‹è½½å›¾ç‰‡
    let response = reqwest::get(image_url)
        .await
        .map_err(|e| format!("ç½‘ç»œè¯·æ±‚å¤±è´¥: {}", e))?;

    if !response.status().is_success() {
        return Err(format!("HTTPé”™è¯¯: {}", response.status()).into());
    }

    let image_data = response
        .bytes()
        .await
        .map_err(|e| format!("è¯»å–å“åº”æ•°æ®å¤±è´¥: {}", e))?;

    if convert_to_webp {
        // è½¬æ¢ä¸ºwebpæ ¼å¼
        convert_to_webp_format(&image_data, local_path).await?;
    } else {
        // ç›´æ¥ä¿å­˜åŸæ ¼å¼
        tokio::fs::write(local_path, &image_data)
            .await
            .map_err(|e| format!("ä¿å­˜æ–‡ä»¶å¤±è´¥: {}", e))?;
    }

    Ok(())
}

// è½¬æ¢å›¾ç‰‡ä¸ºwebpæ ¼å¼
async fn convert_to_webp_format(
    image_data: &[u8],
    output_path: &str,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    use image::io::Reader as ImageReader;
    use std::io::Cursor;

    // åœ¨tokioçº¿ç¨‹æ± ä¸­æ‰§è¡Œå›¾ç‰‡è½¬æ¢
    let output_path_owned = output_path.to_string();
    let image_data_owned = image_data.to_vec();

    tokio::task::spawn_blocking(move || {
        // ä»å­—èŠ‚æ•°æ®è¯»å–å›¾ç‰‡
        let reader = ImageReader::new(Cursor::new(&image_data_owned))
            .with_guessed_format()
            .map_err(|e| format!("æ— æ³•è¯†åˆ«å›¾ç‰‡æ ¼å¼: {}", e))?;

        let img = reader
            .decode()
            .map_err(|e| format!("å›¾ç‰‡è§£ç å¤±è´¥: {}", e))?;

        // è½¬æ¢ä¸ºRGBæ ¼å¼
        let rgb_image = img.to_rgb8();

        // ä½¿ç”¨webpç¼–ç å™¨ç¼–ç 
        let webp_data =
            webp::Encoder::from_rgb(rgb_image.as_raw(), rgb_image.width(), rgb_image.height())
                .encode(75.0); // è´¨é‡75

        // ä¿å­˜webpæ–‡ä»¶ (éœ€è¦è§£å¼•ç”¨WebPMemory)
        std::fs::write(output_path_owned, &*webp_data)
            .map_err(|e| format!("ä¿å­˜webpæ–‡ä»¶å¤±è´¥: {}", e))?;

        Ok::<(), Box<dyn std::error::Error + Send + Sync>>(())
    })
    .await
    .map_err(|e| format!("å›¾ç‰‡è½¬æ¢ä»»åŠ¡å¤±è´¥: {}", e))?
}

// ä¿æŒåŸæœ‰å‡½æ•°ç”¨äºå‘åå…¼å®¹
async fn download_image_to_local(
    image_url: &str,
) -> Result<String, Box<dyn std::error::Error + Send + Sync>> {
    // åˆ›å»ºä¸€ä¸ªé»˜è®¤çš„collectioné…ç½®ç”¨äºå…¼å®¹æ€§
    let default_collection = Collection {
        id: None,
        collect_name: "default".to_string(),
        collect_url: "".to_string(),
        collect_type: 1,
        collect_mid: 1,
        collect_appid: "".to_string(),
        collect_appkey: "".to_string(),
        collect_param: "".to_string(),
        collect_filter: "".to_string(),
        collect_filter_from: "".to_string(),
        collect_opt: 0,
        collect_sync_pic_opt: 1,
        collect_remove_ad: 1,
        collect_convert_webp: 0,   // é»˜è®¤ä¸è½¬æ¢webp
        collect_download_retry: 3, // é»˜è®¤é‡è¯•3æ¬¡
        collect_status: 1,
        created_at: mongodb::bson::DateTime::now(),
        updated_at: mongodb::bson::DateTime::now(),
    };

    download_image_to_local_with_config(image_url, &default_collection).await
}

// é‡‡é›†å•ä¸ªè§†é¢‘è¯¦æƒ…ï¼ˆä¿ç•™åŸæœ‰å‡½æ•°ç”¨äºå…¼å®¹æ€§ï¼‰
pub async fn collect_video_detail(
    db: web::Data<Database>,
    api_url: &str,
    vod_id: &str,
    source_flag: &str,
) -> Result<bool, Box<dyn std::error::Error>> {
    // æ„å»ºè¯¦æƒ…API URL
    let detail_url = format!("{}?ac=detail&h=24&ids={}", api_url, vod_id);

    // è·å–è§†é¢‘è¯¦æƒ…
    let response = reqwest::get(&detail_url).await?;
    let api_response: JsonResponse<VodApiListEntry> = response.json().await?;

    if api_response.code != 1 || api_response.list.is_empty() {
        return Err("è·å–è§†é¢‘è¯¦æƒ…å¤±è´¥".into());
    }

    let vod_data = &api_response.list[0];

    // æŸ¥æ‰¾åˆ†ç±»ç»‘å®š
    let bindings_collection = db.collection::<Binding>("bindings");
    let binding = bindings_collection
        .find_one(
            doc! {
                "source_flag": source_flag,
                "external_id": vod_data.type_id.to_string()
            },
            None,
        )
        .await?;

    let local_type_id = match binding {
        Some(b) => b.local_type_id,
        None => {
            eprintln!(
                "æœªæ‰¾åˆ°åˆ†ç±»ç»‘å®š: source_flag={}, external_id={}",
                source_flag, vod_data.type_id
            );
            return Err("æœªæ‰¾åˆ°åˆ†ç±»ç»‘å®š".into());
        }
    };

    // æ£€æŸ¥è§†é¢‘æ˜¯å¦å·²å­˜åœ¨
    let vods_collection = db.collection::<Vod>("vods");
    let existing_vod = vods_collection
        .find_one(
            doc! {
                "vod_name": &vod_data.vod_name
            },
            None,
        )
        .await?;

    let current_time = DateTime::from_millis(
        SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_millis() as i64,
    );

    if let Some(mut existing) = existing_vod {
        // æ›´æ–°ç°æœ‰è§†é¢‘ - ä½¿ç”¨VodApiListEntryä¸­çš„æ‰€æœ‰å¯ç”¨å­—æ®µ
        existing.vod_name = vod_data.vod_name.clone();
        existing.type_id = local_type_id;
        existing.vod_status = 1; // é»˜è®¤çŠ¶æ€
                                 // æ›´æ–°æ‰€æœ‰å¯ç”¨å­—æ®µ
        existing.vod_remarks = Some(vod_data.vod_remarks.clone());
        if let Some(ref pubdate) = vod_data.vod_pubdate {
            existing.vod_pubdate = current_time;
        }
        if let Some(ref class) = vod_data.vod_class {
            existing.vod_class = Some(class.clone());
        }
        if let Some(ref pic) = vod_data.vod_pic {
            existing.vod_pic = Some(pic.clone());
        }
        if let Some(ref actor) = vod_data.vod_actor {
            existing.vod_actor = Some(actor.clone());
        }
        if let Some(ref director) = vod_data.vod_director {
            existing.vod_director = Some(director.clone());
        }
        if let Some(ref area) = vod_data.vod_area {
            existing.vod_area = Some(area.clone());
        }
        if let Some(ref lang) = vod_data.vod_lang {
            existing.vod_lang = Some(lang.clone());
        }
        if let Some(ref year) = vod_data.vod_year {
            existing.vod_year = Some(year.clone());
        }
        if let Some(ref content) = vod_data.vod_content {
            existing.vod_content = Some(content.clone());
        }
        // è§£ææ’­æ”¾åœ°å€
        if !vod_data.vod_play_from.is_empty() {
            existing.vod_play_urls =
                parse_play_urls(&vod_data.vod_play_from, &vod_data.vod_play_url);
        }

        vods_collection
            .replace_one(doc! { "_id": existing.id }, &existing, None)
            .await?;
    } else {
        // åˆ›å»ºæ–°è§†é¢‘ - åªä½¿ç”¨VodApiListEntryä¸­å®é™…å­˜åœ¨çš„å­—æ®µ
        let new_vod = Vod {
            id: None,
            vod_name: vod_data.vod_name.clone(),
            type_id: local_type_id,
            vod_status: vod_data.vod_status.unwrap_or(1),
            vod_class: vod_data.vod_class.clone(),
            vod_pic: vod_data.vod_pic.clone(),
            vod_actor: vod_data.vod_actor.clone(),
            vod_director: vod_data.vod_director.clone(),
            vod_remarks: Some(vod_data.vod_remarks.clone()),
            vod_pubdate: current_time.clone(),
            vod_area: vod_data.vod_area.clone(),
            vod_lang: vod_data.vod_lang.clone(),
            vod_year: vod_data.vod_year.clone(),
            vod_content: vod_data.vod_content.clone(),
            vod_hits: Some(0),
            vod_hits_day: Some(0),
            vod_hits_week: Some(0),
            vod_hits_month: Some(0),
            vod_score: Some("0.0".to_string()),
            vod_play_urls: parse_play_urls(&vod_data.vod_play_from, &vod_data.vod_play_url),
        };

        vods_collection.insert_one(&new_vod, None).await?;
    }

    Ok(true)
}
